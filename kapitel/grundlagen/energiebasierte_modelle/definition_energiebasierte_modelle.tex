\subsubsection{Definition: energiebasierte Modelle und energiebasiertes Lernen}

Energiebasierte Modelle werden im maschinellen Lernen eingesetzt und nutzen eine Energiefunktion, die jeder möglichen Variablenkonfiguration einen skalaren Energiewert zuweist. In einem neuronalen Netz könnten diese Variablen beispielsweise die Eingabegrößen, die Parameter, versteckte Variablen sowie die Ausgabewerte umfassen. Bei der Inferenz des Modells werden zunächst die Eingabevariablen festgelegt, bevor ein Minimum der Energiefunktion bestimmt wird. Sobald dieses Minimum gefunden ist, lässt sich die Ausgabe des Modells anhand der Ausgabevariablen ablesen.

Das Training eines energiebasierten Modells erfolgt durch Anpassung seiner Energiefunktion, sodass korrekte Werte mit geringeren Energien und falsche Werte mit höheren Energien bewertet werden (\cite{Lecun2006}). Zu den ersten vorgestellten energiebasierten Modellen zählen das Hopfield-Netzwerk (\cite{Hopfield1984}) sowie die darauf basierende Boltzmann-Maschine (\cite{Ackley1985}).
