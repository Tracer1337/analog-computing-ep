\paragraph{Mathematische Grundlagen}

\textbf{TODO: Seitenzahlen für Quellenangaben}

Ein Verfahren zum Trainieren \glspl{ebm} stellt das \gls{eqprop} dar. In diesem Verfahren wird der Gradient einer Energiefunktion bestimmt und damit die Parameter des Modells angepasst. Die Vorhersagen des Modells werden aus dem Datenpunkt und den Parametern impliziert anstelle diese explizit zu definieren, weshalb sich dieses Verfahren besonders für die Anwendung auf analogen Computern eignet. \cite{Scellier2017}

Der Zustand des Modells wird durch den Vektor \(s\) dargestellt, \(v\) gibt die Eingabe-Variablen an und \(\theta\) steht für die Parameter des Modells. Die Zustandsvariable \(s\) verändert sich über Zeit, sodass die Energiefunktion \(E(\theta,v,s)\) minimiert wird. Neben der Energiefunktion wird auch eine Kosten-Funktion \(C(\theta,v,s)\) definiert, welche die Diskrepanz zwischen der Ausgabe des Modells und den Zielwerten angibt. Liefert die Energiefunktion für eine Konfiguration an Variablen eine kleinere Energie, so sollte auch der Wert der Kosten-Funktion geringer sein. Zusätzlich wird der Einfluss-Parameter \(\beta\) definiert, der als Skalierungsfaktor für die Kostenfunktion dient. Das Equilibrium Propagation definiert nun eine Gesamtenergiefunktion \(F\) als:

\[F(\theta,v,\beta,s):=E(\theta,v,s)+\beta C(\theta,v,s)\]

Die Fixpunkte des Modells werden in der Form \(s_{(\theta,v)}^\beta\) dargestellt, und stehen für jeweils ein lokales Minimum der Gesamtenergiefunktion \(F\). Mit \(\beta=0\) ergibt sich \(s_{(\theta,v)}^0\), ein Minimum der Energiefunktion \(E\) und damit die Vorhersage des Modells. \cite{Scellier2017}

Die Zielfunktion \(J\), die im Equilibrium Propagation optimiert werden soll, lautet:

\[J(\theta,v)=C(\theta,v,s_{(\theta,v)})^0\]

Die Kostenfunktion gibt die Qualität des Modells zu einem beliebigen \(\beta\) an, \(J\) hingegen nur für die Vorhersage mit \(\beta=0\). Der Gradient der Zielfunktion \(J\) nach \(\theta\) ist nun durch folgende Formel gegeben:

\[\frac{\partial J}{\partial \theta}(\theta,v)=\lim\limits_{\beta \to 0}\frac{1}{\beta}\left(\frac{\partial F}{\partial \theta}(\theta,v,\beta,s_{(\theta,v)}^\beta)-\frac{\partial F}{\partial \theta}(\theta,v,\beta,s_{(\theta,v)}^0)\right)\]

Anhand dieser Formel lässt sich die Änderungsrate von \(\theta\) ableiten:

\[\Delta\theta\propto -\frac{1}{\beta}\left(\frac{\partial F}{\partial \theta}(\theta,v,\beta,s_{(\theta,v)}^\beta)-\frac{\partial F}{\partial \theta}(\theta,v,\beta,s_{(\theta,v)}^0)\right)\]

Hieraus ergibt sich in der Praxis unter Anwendung am \gls{hopfieldnetzwerk} ein zweiphasiger Lernprozess. In der ersten Phase wird Inferenz durchgeführt, also ein Minimum der Energiefunktion gesucht und die Ausgabe des Netzes ausgelesen. In dieser Phase ist \(\beta=0\). Die zweite Phase setzt \(\beta>0\) und lenkt damit die Ausgabe des Netzes in Richtung des Zielwertes. Die versteckten Variablen des Netzes befinden sich zu Beginn dieser Phase im Gleichgewicht, die Störung an den Ausgabe-Variablen propagiert aber über Zeit zu den versteckten Variablen. Wird ein Netzwerk mit mehreren Ebenen betrachtet, so propagiert die Störung rückwärts durch das Netz, was auch als \gls{backpropagation} bezeichnet werden kann. \cite{Scellier2017}
