\subsubsection{Notwendige Modifikationen am Netzwerk für Equilibrium Propagation}

Das \gls{eqprop} definiert mit \(C:=\frac{1}{2}\| y-d\| ^2\) eine Kostenfunktion des \gls{hopfieldnetzwerk}, welche mit \(-\beta\frac{\partial C}{\partial y_i}=\beta(d_i-y_i)\) auf die Dynamik der Zustände wirkt. Wie dieser Term in Simulink abgebildet werden kann, ist bereits im Anhang \ref{Anhang} dargestellt.

Zusätzlich werden die Energiefunktion sowie die Kostenfunktion mithilfe von Matlab-Funktionsblöcken an das Netzwerk angeschlossen, und zur Auswertung bereitgestellt. Mithilfe dieser Auswertungen kann die Funktionsweise des Netzwerks hinsichtlich der Annahme \(\frac{dF}{dt}\leq{0}\) \cite[vgl. S. 3]{Scellier2017} validiert werden.

Die Gewichtungen wurden bisher als konstanten implementiert, müssen aber für die Anwendung eines Lernalgorithmus dynamisch anpassbar sein. Die von \citeauthor{Scellier2017} vorgestellte Lernregel \(\Delta W_{ij}\) kann auch als Integration der Lernregel \(\frac{dW_{ij}}{dt}\) interpretiert werden \cite[vgl. S. 5]{Scellier2017}, weshalb zur Implementierung der Gewichtungen Integratoren zum Einsatz kommen können (gleiches gilt für die Bias-Werte). Typischerweise werden Gewichtungen in neuronalen Netzen mit Zufallswerten initialisiert, was in Simulink durch den Block "`Random Number"' möglich ist. Da das hier implementierte \gls{hopfieldnetzwerk} mit einem Vektor als Repräsentation der Zustände arbeitet, müssen die Gewichtungen durch einen Matlab-Funktionsblock zu einer Matrix zusammengesetzt werden (siehe Anhang \ref{Anhang}). Das angepasste Netzwerk ist im Anhang \ref{Anhang} abgebildet.
