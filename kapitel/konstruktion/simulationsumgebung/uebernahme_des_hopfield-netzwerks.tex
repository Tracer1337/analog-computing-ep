\paragraph{Übernahme des Hopfield-Netzwerks}
\label{chap:Übernahme des Hopfield-Netzwerks}

Im Folgenden soll die von \citeauthor{Scellier2017} vorgestellte Dynamik \(\frac{ds}{dt}\) eines \gls{hopfieldnetzwerk} (wie bereits im Kapitel \ref{chap:Theoretische Anwendung am Beispiel eines Hopfield-Netzwerks} gezeigt) in Simulink implementiert werden.

Um die Zustandsvariablen \(s\) darzustellen, können Integratoren genutzt werden, welche standardmäßig über Zeit integrieren. Über die Initialwerte dieser Integratoren wird die Eingabe in das \gls{hopfieldnetzwerk} definiert, welche dann über die Dynamik zu einem Fixpunkt gelangen:

\[\frac{ds}{dt}=-\frac{\partial{E}}{\partial{s}}-\beta\frac{\partial{C}}{\partial{s}}\]

Um diesen Term abzubilden werden die Gewichtungen benötigt, diese und ihre Initialwerte werden vorerst über Konstanten implementiert. Als Aktivierungsfunktion kommt hier eine Sigmoidfunktion, die logistische Funktion \(\rho(x)=\frac{1}{1+e^{-x}}\), zum Einsatz, da sie Werte im Bereich 0 - 1 ausgibt und sich damit für den Einsatz auf analogen Computern eignet. Diese Funktion kann praktisch potenziell über einen Funktionsgenerator und in Simulink über einen Matlab-Funktionsblock (Siehe Anhang \ref{Anhang}) erzeugt werden. Zusätzlich zur Aktivierungsfunktion wird auch ihre Ableitung \(\rho'(x)=\rho(x)(1-\rho(x))\) benötigt, welche auf selbe Weise implementiert wird.

Diese Komponenten, die Zustände, Gewichtungen (und Bias) und die Aktivierungsfunktion werden nun gemäß der Formel \ref{Formel} mit Summierern und Multiplizierern miteinander verschaltet. Ein solches Netzwerk mit zwei Neuronen ist im Anhang \ref{Anhang} zu sehen. Die gezeigte Schaltung implementiert noch nicht die Kostenfunktion, erreicht aber bereits mit zwei Neuronen eine hohe Komplexität. Ein Netzwerk mit drei Neuronen, welches zusätzlich die Kostenfunktion implementiert ist im Anhang \ref{Anhang} dargestellt, wobei der Bias zur Übersichtlichkeit weggelassen wurde. Aus dieser Schaltung wird ersichtlich, dass die Implementierung eines \gls{hopfieldnetzwerk} mit analogen Rechenelementen bereits mit wenigen Neuronen sehr komplex und unübersichtlich wird, weshalb im Weiteren von Vektoren und Matrizen innerhalb von Simulink Gebrauch gemacht wird, siehe Anhang \ref{Anhang}. Durch die Eingabe verschieden großer Vektoren in den "`Training"'-Block, kann so die Anzahl der Neuronen des Netzwerks geändert werden. Diese Implementierung bietet potenziell auch die Möglichkeit, Trainingsdaten dynamisch aus der Matlab-Umgebung zu laden.
