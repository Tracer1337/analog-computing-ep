\subsubsection{Umgang mit unerwarteten Ergebnissen}

Die ursprüngliche Arbeit über \ac{ep} beschreibt neben der Lernregel \(\Delta W_{ij}\) auch eine kontinuierliche Interpretation dieser im Zusammenhang mit der sog. Spike-Timing Dependent Plasticity \cite{Scellier2017}. Dafür wird \(\Delta W_{ij}\) als kontinuierliche Dynamik der Gewichte beschrieben, worauf die Konstruktion des \ac{ep} in dieser Arbeit aufbaut. Zusammen mit dem \ac{eqspike} stellte \citeauthor{Martin2020} eine Lernregel \(\frac{dW_{ij}}{dt}\) auf, welche als Variation des \ac{ep} lokal in Ort und Zeit arbeitet und sich somit für analoge Computer eignet. Die Modellierung dieser Lernregel in Simulink führt aber, wie in Kapitel \ref{chap:Umsetzung der theoretischen Modelle in der Simulationssoftware} gezeigt, zu Problemen, da die Gewichte nicht konvergieren und die Ergebnisse damit unbrauchbar werden. Aufgrund dessen wurde auf diese kontinuierliche Lernregel verzichtet, und das diskrete Modell, vorgestellt von \citeauthor{Ernoult2020} in ihrer Arbeit über \ac{c-ep}, verwendet.

Diese Annäherung hat sich, wie in Kapitel \ref{chap:Validierung des Algorithmus durch Testläufe} gezeigt, für Netzwerke mit wenigen Neuronen als funktionsfähig erwiesen, kann aber bei größeren Modellen an Genauigkeit verlieren. Möglicherweise kann die Genauigkeit durch eine Verringerung der Zeitdifferenz der verglichenen Zustände des Modells mit \(t\) und \(t+1\) verbessert werden, eine mathematisch fehlerfreie Lösung ist aber nur mit einer Lösung von \(\frac{dW_{ij}}{dt}\) für die von \citeauthor{Scellier2017} beschrieben Dynamik des \ac{hnn} möglich. Da die aktuelle Forschung dafür aber noch keine Lösung bereithält, bleibt dieses Problem hier ungelöst.
